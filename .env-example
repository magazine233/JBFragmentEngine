# .env.example
# Copy this file to .env and update with your values

# Typesense Configuration
TYPESENSE_API_KEY=your-secure-api-key-here

# Scraper Configuration
TARGET_URL=https://my.gov.au
MAX_DEPTH=3
MAX_LINKS_PER_PAGE=10
CONCURRENCY=5

# API Configuration
PORT=3000
CORS_ORIGIN=*
NODE_ENV=production

# LLM Providers
# Local Ollama endpoint
# - Linux Docker default bridge: http://172.17.0.1:11434
# - Mac/Windows Docker: http://host.docker.internal:11434
OLLAMA_URL=http://172.17.0.1:11434
# Remote LLM API (optional). Set to enable /api/llm OpenAI provider
OPENAI_API_KEY=

# LiteLLM (recommended): unify local + remote models via OpenAI-compatible API
# If set, API will route all /api/llm/chat requests through LiteLLM
LITELLM_URL=
LITELLM_API_KEY=
